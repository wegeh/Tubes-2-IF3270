{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f895aef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0361f632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (50000, 32, 32, 3) (50000, 1)\n",
      "Test shape: (10000, 32, 32, 3) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "(x_trainval, y_trainval), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print('Train shape:', x_trainval.shape, y_trainval.shape)\n",
    "print('Test shape:', x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "628d91ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (40000, 32, 32, 3), Val: (10000, 32, 32, 3), Test: (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_trainval, y_trainval, test_size=0.2, random_state=42, stratify=y_trainval)\n",
    "\n",
    "print(f\"Train: {x_train.shape}, Val: {x_val.shape}, Test: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "351ceb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_val = x_val.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40737919",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Flatten, Dense\n",
    "\n",
    "def build_model(input_shape, num_conv=3, filters=[32,64,128], kernel_sizes=[(3,3)]*3, pooling_type='max'):\n",
    "    model = Sequential()\n",
    "    for i in range(num_conv):\n",
    "        if i == 0:\n",
    "            model.add(Conv2D(filters[i], kernel_sizes[i], activation='relu', input_shape=input_shape, padding='same'))\n",
    "        else:\n",
    "            model.add(Conv2D(filters[i], kernel_sizes[i], activation='relu', padding='same'))\n",
    "        if pooling_type == 'max':\n",
    "            model.add(MaxPooling2D((2,2)))\n",
    "        else:\n",
    "            model.add(AveragePooling2D((2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94bfa630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/williamglory/Desktop/IF SEM 6/ML/Tubes-2-IF3270/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-05-29 11:57:20.343341: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-05-29 11:57:20.343630: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 - 9s - 15ms/step - accuracy: 0.4535 - loss: 1.5292 - val_accuracy: 0.5665 - val_loss: 1.2405\n",
      "Epoch 2/10\n",
      "625/625 - 8s - 13ms/step - accuracy: 0.5961 - loss: 1.1493 - val_accuracy: 0.6225 - val_loss: 1.0831\n",
      "Epoch 3/10\n",
      "625/625 - 8s - 13ms/step - accuracy: 0.6466 - loss: 1.0125 - val_accuracy: 0.6438 - val_loss: 1.0307\n",
      "Epoch 4/10\n",
      "625/625 - 8s - 13ms/step - accuracy: 0.6772 - loss: 0.9248 - val_accuracy: 0.6562 - val_loss: 0.9996\n",
      "Epoch 5/10\n",
      "625/625 - 8s - 13ms/step - accuracy: 0.7017 - loss: 0.8574 - val_accuracy: 0.6654 - val_loss: 0.9853\n",
      "Epoch 6/10\n",
      "625/625 - 9s - 14ms/step - accuracy: 0.7222 - loss: 0.8018 - val_accuracy: 0.6731 - val_loss: 0.9679\n",
      "Epoch 7/10\n",
      "625/625 - 9s - 14ms/step - accuracy: 0.7405 - loss: 0.7507 - val_accuracy: 0.6859 - val_loss: 0.9476\n",
      "Epoch 8/10\n",
      "625/625 - 9s - 14ms/step - accuracy: 0.7574 - loss: 0.7044 - val_accuracy: 0.6861 - val_loss: 0.9451\n",
      "Epoch 9/10\n",
      "625/625 - 9s - 14ms/step - accuracy: 0.7721 - loss: 0.6612 - val_accuracy: 0.6866 - val_loss: 0.9569\n",
      "Epoch 10/10\n",
      "625/625 - 9s - 14ms/step - accuracy: 0.7864 - loss: 0.6243 - val_accuracy: 0.6833 - val_loss: 0.9764\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = build_model(\n",
    "    input_shape=(32,32,3),\n",
    "    num_conv=2,                 \n",
    "    filters=[32,64],       \n",
    "    kernel_sizes=[(3,3)]*2,    \n",
    "    pooling_type='max'          \n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    validation_data=(x_val, y_val),\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "model.save_weights('weights_compare.weights.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34fdc2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1-score (from scratch): 0.6827\n",
      "\u001b[1m 61/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-29 12:17:21.418504: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n",
      "2025-05-29 12:17:21.418747: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Macro F1-score (keras): 0.6827\n",
      "\n",
      "Sample comparison [True, Scratch, Keras]:\n",
      "0: 3  |  3  |  3\n",
      "1: 8  |  8  |  8\n",
      "2: 8  |  0  |  0\n",
      "3: 0  |  8  |  8\n",
      "4: 6  |  4  |  4\n",
      "5: 6  |  6  |  6\n",
      "6: 1  |  1  |  1\n",
      "7: 6  |  6  |  6\n",
      "8: 3  |  3  |  3\n",
      "9: 1  |  1  |  1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from CNNScratch import CNNScratch  \n",
    "\n",
    "keras_model = build_model(\n",
    "    input_shape=(32,32,3),\n",
    "    num_conv=2,                       \n",
    "    filters=[32,64],        \n",
    "    kernel_sizes=[(3,3), (3,3)],\n",
    "    pooling_type='max'\n",
    ")\n",
    "keras_model.load_weights('weights_compare.weights.h5')  \n",
    "\n",
    "scratch_model = CNNScratch(keras_model)\n",
    "\n",
    "batch_size = 32\n",
    "y_pred_scratch_prob = scratch_model.forward(x_test, batch_size=batch_size)  \n",
    "y_pred_scratch = np.argmax(y_pred_scratch_prob, axis=1)\n",
    "y_true = y_test.flatten()\n",
    "\n",
    "f1_scratch = f1_score(y_true, y_pred_scratch, average='macro')\n",
    "print(f\"Macro F1-score (from scratch): {f1_scratch:.4f}\")\n",
    "\n",
    "y_pred_keras_prob = keras_model.predict(x_test, batch_size=batch_size)\n",
    "y_pred_keras = np.argmax(y_pred_keras_prob, axis=1)\n",
    "f1_keras = f1_score(y_true, y_pred_keras, average='macro')\n",
    "print(f\"Macro F1-score (keras): {f1_keras:.4f}\")\n",
    "\n",
    "print(\"\\nSample comparison [True, Scratch, Keras]:\")\n",
    "for i in range(10):\n",
    "    print(f\"{i}: {y_true[i]}  |  {y_pred_scratch[i]}  |  {y_pred_keras[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
