{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95c4802e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mDropoutLayer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DropoutLayer\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mDenseLayer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DenseLayer\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m f1_score\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from ScratchRnn import ScratchRNNModel\n",
    "from EmbeddingLayer import EmbeddingLayer\n",
    "from SimpleRnnLayer import SimpleRNNLayer\n",
    "from BidirectionalLayer import BidirectionalLayer\n",
    "from DropoutLayer import DropoutLayer\n",
    "from DenseLayer import DenseLayer\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5afff5b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 73, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:73\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 73\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pywrap_tensorflow_internal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Externally in opensource we must enable exceptions to load the shared object\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# by exposing the PyInit symbols with pybind. This error will only be\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# This logic is used in other internal projects using py_extension.\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m SEED \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m42\u001b[39m\n\u001b[0;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTF_DETERMINISTIC_OPS\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\__init__.py:40\u001b[0m\n\u001b[0;32m     37\u001b[0m _os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mENABLE_RUNTIME_UPTIME_TELEMETRY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:88\u001b[0m\n\u001b[0;32m     86\u001b[0m     sys\u001b[38;5;241m.\u001b[39msetdlopenflags(_default_dlopen_flags)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m---> 88\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     89\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraceback\u001b[38;5;241m.\u001b[39mformat_exc()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     90\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFailed to load the native TensorFlow runtime.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     91\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee https://www.tensorflow.org/install/errors \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     92\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfor some common causes and solutions.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     93\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you need help, create an issue \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     94\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mat https://github.com/tensorflow/tensorflow/issues \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     95\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mand include the entire stack trace above this error message.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 73, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "SEED = 42\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0840798b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rnn_model_from_keras(keras_model, dropout_rate=0.5) -> ScratchRNNModel:\n",
    "    layers = []\n",
    "    \n",
    "    # 1. Embedding Layer\n",
    "    embedding_keras_layer = keras_model.layers[1]\n",
    "    embedding_weights = embedding_keras_layer.get_weights()[0]\n",
    "    layers.append(EmbeddingLayer(embedding_weights))\n",
    "    \n",
    "    # 2. RNN Layers\n",
    "    rnn_layer_idx_start = 2 \n",
    "    current_keras_idx = rnn_layer_idx_start\n",
    "    \n",
    "    while 'rnn' in keras_model.layers[current_keras_idx].name or 'bidirectional' in keras_model.layers[current_keras_idx].name:\n",
    "        keras_layer = keras_model.layers[current_keras_idx]\n",
    "        \n",
    "        if 'bidirectional' in keras_layer.name:\n",
    "            # Layer Bidirectional\n",
    "            forward_rnn = keras_layer.forward_layer\n",
    "            backward_rnn = keras_layer.backward_layer\n",
    "            \n",
    "            fw_weights = forward_rnn.get_weights()\n",
    "            bw_weights = backward_rnn.get_weights()\n",
    "            \n",
    "            rnn_units = fw_weights[1].shape[0]\n",
    "            \n",
    "            forward_layer = SimpleRNNLayer(W_xh=fw_weights[0], W_hh=fw_weights[1], b_h=fw_weights[2], rnn_units=rnn_units)\n",
    "            backward_layer = SimpleRNNLayer(W_xh=bw_weights[0], W_hh=bw_weights[1], b_h=bw_weights[2], rnn_units=rnn_units)\n",
    "            \n",
    "            layers.append(BidirectionalLayer(forward_layer, backward_layer))\n",
    "            print(f\"Layer {len(layers)-1}: Bidirectional(SimpleRNN), units: {rnn_units}\")\n",
    "            \n",
    "        else: # Layer Unidirectional\n",
    "            weights = keras_layer.get_weights()\n",
    "            rnn_units = weights[1].shape[0]\n",
    "            rnn_layer = SimpleRNNLayer(W_xh=weights[0], W_hh=weights[1], b_h=weights[2], rnn_units=rnn_units)\n",
    "            layers.append(rnn_layer)\n",
    "            print(f\"Layer {len(layers)-1}: SimpleRNN, units: {rnn_units}\")\n",
    "            \n",
    "        current_keras_idx += 1\n",
    "        if current_keras_idx >= len(keras_model.layers):\n",
    "            break\n",
    "\n",
    "    # 3. Dropout Layer \n",
    "    layers.append(DropoutLayer(rate=dropout_rate))\n",
    "    print(f\"Layer {len(layers)-1}: Dropout, rate: {dropout_rate}\")\n",
    "\n",
    "    # 4. Dense Layer\n",
    "    dense_keras_layer = [l for l in keras_model.layers if 'dense' in l.name][-1]\n",
    "    dense_weights, dense_bias = dense_keras_layer.get_weights()\n",
    "    layers.append(DenseLayer(weights=dense_weights, bias=dense_bias, activation='softmax'))\n",
    "    print(f\"Layer {len(layers)-1}: Dense, shape: {dense_weights.shape}, activation: softmax\")\n",
    "\n",
    "    return ScratchRNNModel(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf94fadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compare_models(keras_model, scratch_model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Membandingkan prediksi dan skor F1 dari model Keras dan model scratch.\n",
    "    \"\"\"\n",
    "    print(\"\\nMemperoleh prediksi dari model Keras...\")\n",
    "    keras_pred_probs = keras_model.predict(X_test, verbose=0)\n",
    "    keras_predictions = np.argmax(keras_pred_probs, axis=1)\n",
    "    \n",
    "    print(\"Memperoleh prediksi dari model scratch...\")\n",
    "    # Menggunakan metode .predict() dari SimpleRNNModel (yang memanggil .forward(training=False))\n",
    "    scratch_pred_probs = scratch_model.predict(X_test) \n",
    "    scratch_predictions = np.argmax(scratch_pred_probs, axis=1)\n",
    "    \n",
    "    # Hitung skor F1\n",
    "    keras_f1 = f1_score(y_test, keras_predictions, average='macro')\n",
    "    scratch_f1 = f1_score(y_test, scratch_predictions, average='macro')\n",
    "    \n",
    "    print(f\"\\nSkor F1 Keras: {keras_f1:.6f}\")\n",
    "    print(f\"Skor F1 Scratch: {scratch_f1:.6f}\")\n",
    "    \n",
    "    difference = abs(keras_f1 - scratch_f1)\n",
    "    print(f\"Perbedaan F1 (absolut): {difference:.8f}\") # Tingkatkan presisi untuk perbedaan kecil\n",
    "    \n",
    "    # Cek kesamaan probabilitas output (lebih ketat)\n",
    "    prob_diff = np.abs(keras_pred_probs - scratch_pred_probs).max()\n",
    "    print(f\"Perbedaan maksimum probabilitas output: {prob_diff:.8e}\")\n",
    "\n",
    "    if prob_diff < 1e-6: # Toleransi untuk perbedaan floating point\n",
    "        print(\"Output probabilitas model Keras dan Scratch sangat mirip.\")\n",
    "    else:\n",
    "        print(\"PERINGATAN: Output probabilitas model Keras dan Scratch memiliki perbedaan signifikan.\")\n",
    "        \n",
    "    return keras_f1, scratch_f1, keras_predictions, scratch_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017fda92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.rnn.preprocessing.text_vectorizer import create_text_vectorizer\n",
    "\n",
    "\n",
    "def prepare_test_data(test_df, train_df, vocab_size, sequence_length):\n",
    "    \"\"\"\n",
    "    Mempersiapkan data tes: membuat vectorizer, memetakan label, dan membuat sekuens.\n",
    "    \"\"\"\n",
    "    print(\"\\nMembuat text vectorizer menggunakan data training...\")\n",
    "    # Pastikan create_text_vectorizer menggunakan vocab_size dan sequence_length yang konsisten\n",
    "    # dan mengembalikan objek Keras TextVectorization atau yang kompatibel\n",
    "    vectorizer = create_text_vectorizer(\n",
    "        train_df['text'].values, \n",
    "        max_tokens=vocab_size, \n",
    "        output_sequence_length=sequence_length\n",
    "    )\n",
    "    \n",
    "    # Pemetaan label\n",
    "    label_map = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "    y_test_mapped = test_df['label'].map(label_map).values\n",
    "    \n",
    "    # Ubah teks menjadi tensor dan terapkan vectorizer\n",
    "    test_texts_tensor = tf.convert_to_tensor(test_df['text'].values, dtype=tf.string)\n",
    "    test_sequences = vectorizer(test_texts_tensor).numpy() # .numpy() untuk mendapatkan array NumPy\n",
    "    \n",
    "    return test_sequences, y_test_mapped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a0d122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.rnn.keras_model import build_simple_rnn_model\n",
    "\n",
    "VOCAB_SIZE = 10000        \n",
    "SEQ_LENGTH = 100          \n",
    "EMBEDDING_DIM = 128       \n",
    "RNN_UNITS = 32            \n",
    "NUM_CLASSES = 3           \n",
    "NUM_LAYERS = 3            \n",
    "BIDIRECTIONAL = True      \n",
    "KERAS_DROPOUT_RATE = 0.5  \n",
    "\n",
    "print(\"Parameter Model:\")\n",
    "print(f\"  VOCAB_SIZE: {VOCAB_SIZE}, SEQ_LENGTH: {SEQ_LENGTH}, EMBEDDING_DIM: {EMBEDDING_DIM}\")\n",
    "print(f\"  RNN_UNITS: {RNN_UNITS}, NUM_CLASSES: {NUM_CLASSES}, NUM_LAYERS: {NUM_LAYERS}\")\n",
    "print(f\"  BIDIRECTIONAL: {BIDIRECTIONAL}, KERAS_DROPOUT_RATE: {KERAS_DROPOUT_RATE}\")\n",
    "\n",
    "base_path = '.' \n",
    "test_df = pd.read_csv(os.path.join(base_path, 'dataset/test.csv'))\n",
    "train_df = pd.read_csv(os.path.join(base_path, \"dataset/train.csv\"))\n",
    "print(\"Dataset berhasil dimuat.\")\n",
    "\n",
    "print(\"\\nMempersiapkan data tes...\")\n",
    "X_test, y_test = prepare_test_data(test_df, train_df, VOCAB_SIZE, SEQ_LENGTH)\n",
    "\n",
    "print(f\"\\nBentuk data tes (X_test): {X_test.shape}\")\n",
    "print(f\"Bentuk label tes (y_test): {y_test.shape}\")\n",
    "print(f\"Label unik: {np.unique(y_test)}\")\n",
    "\n",
    "print(\"\\nMembangun model Keras...\")\n",
    "keras_model = build_simple_rnn_model(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    rnn_units=RNN_UNITS,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    sequence_length=SEQ_LENGTH,\n",
    "    bidirectional=BIDIRECTIONAL,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dropout_rate=KERAS_DROPOUT_RATE \n",
    ")\n",
    "\n",
    "\n",
    "weights_path = os.path.join(base_path, f'weight_comparison_rnn.weights.h5')\n",
    "print(f\"Mencoba memuat bobot Keras dari: {weights_path}\")\n",
    "keras_model.load_weights(weights_path) \n",
    "print(\"Bobot Keras berhasil dimuat!\")\n",
    "    \n",
    "print(\"\\nRingkasan Model Keras:\")\n",
    "keras_model.summary(line_length=100)\n",
    "\n",
    "print(\"\\nMembuat model scratch menggunakan komponen yang telah direfactor...\")\n",
    "scratch_model = create_rnn_model_from_keras(keras_model, dropout_rate=KERAS_DROPOUT_RATE)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MEMBANDINGKAN MODEL KERAS DAN SCRATCH\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "keras_f1, scratch_f1, keras_preds, scratch_preds = compare_models(keras_model, scratch_model, X_test, y_test)\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"HASIL AKHIR PERBANDINGAN\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Skor F1 Keras: {keras_f1:.6f}\")\n",
    "print(f\"Skor F1 Scratch: {scratch_f1:.6f}\")\n",
    "\n",
    "difference_f1 = abs(keras_f1 - scratch_f1)\n",
    "print(f\"Perbedaan F1 (absolut): {difference_f1:.8f}\")\n",
    "\n",
    "if difference_f1 < 1e-7: \n",
    "    print(\"\\nBERHASIL: Skor F1 model Keras dan Scratch sangat cocok!\")\n",
    "else:\n",
    "    print(\"\\nMASALAH: Skor F1 model Keras dan Scratch TIDAK cocok.\")\n",
    "\n",
    "results_dir = os.path.join(base_path, \"results/comparison\")\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'true_label': y_test,\n",
    "    'keras_pred_label': keras_preds,\n",
    "    'scratch_pred_label': scratch_preds,\n",
    "    'match': keras_preds == scratch_preds\n",
    "})\n",
    "\n",
    "comparison_filename = os.path.join(results_dir, f'model_comparison_L{NUM_LAYERS}_U{RNN_UNITS}_B{int(BIDIRECTIONAL)}.csv')\n",
    "results_df.to_csv(comparison_filename, index=False)\n",
    "print(f\"\\nHasil perbandingan detail disimpan ke: '{comparison_filename}'\")\n",
    "\n",
    "prediction_agreement = results_df['match'].mean()\n",
    "print(f\"Kecocokan prediksi (label): {prediction_agreement:.4f}\")\n",
    "\n",
    "if prediction_agreement == 1.0 and difference_f1 < 1e-7:\n",
    "    print(\"Semua prediksi label cocok dan skor F1 identik. Implementasi scratch berhasil!\")\n",
    "else:\n",
    "    print(\"Ada perbedaan dalam prediksi label atau skor F1. Perlu investigasi lebih lanjut.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
